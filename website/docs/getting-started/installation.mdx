---
title: Installation
sidebar_position: 2
description: How to install ctx-sys on your system
---

# Installation

ctx-sys can be installed via npm and works on macOS, Linux, and Windows.

## Prerequisites

- **Node.js** 18+ (LTS recommended)
- **Git** (for version tracking features)
- **Ollama** (optional, for local embeddings and summarization)

## Quick Install

```bash
npm install -g ctx-sys
```

Verify the installation:

```bash
ctx-sys --version
```

## From Source

```bash
git clone https://github.com/davidfranz/ctx-sys.git
cd ctx-sys
npm install
npm run build
npm link
```

## First-Time Setup

### 1. Initialize a Project

Navigate to your project directory and run:

```bash
cd your-project
ctx-sys init
```

This creates a `.ctx-sys` directory with:
- `config.yaml` - Project configuration
- `ctx-sys.db` - SQLite database (better-sqlite3) for entities, embeddings, and relationships

### 2. Index Your Codebase

```bash
ctx-sys index
```

This parses your source files using tree-sitter, extracts symbols and relationships, and stores everything in the database. First indexing may take a few minutes for large projects.

### 3. Generate Embeddings (Optional)

If Ollama is running with an embedding model:

```bash
ctx-sys embed
```

This generates vector embeddings for semantic search.

### 4. Start the Server

```bash
ctx-sys serve
```

The MCP server starts on stdio mode, ready to connect with Claude Desktop or other MCP clients.

## Configuration Options

### Embedding Provider

ctx-sys supports multiple embedding providers:

#### Ollama (Local, Free)

```bash
# Install Ollama first
curl https://ollama.ai/install.sh | sh

# Pull an embedding model
ollama pull nomic-embed-text

# Optionally pull a summarization model
ollama pull qwen3:0.6b

# ctx-sys will auto-detect Ollama
ctx-sys init
```

#### OpenAI (Cloud)

```bash
# Set your API key
export OPENAI_API_KEY=sk-...

# Configure ctx-sys to use OpenAI
ctx-sys init --provider openai
```

### Project Configuration

Edit `.ctx-sys/config.yaml` to customize:

```yaml
project:
  name: my-project

indexing:
  mode: incremental
  watch: true
  ignore:
    - node_modules
    - dist
  languages:
    - typescript
    - python

embeddings:
  provider: ollama
  model: nomic-embed-text

summarization:
  enabled: true
  provider: ollama
  model: qwen3:0.6b

retrieval:
  default_max_tokens: 4000
  strategies:
    - vector
    - graph
    - fts
```

## CLI Commands Overview

```bash
# Core
ctx-sys init              # Initialize project
ctx-sys index             # Index codebase
ctx-sys search <query>    # Search entities
ctx-sys status            # Show indexing status
ctx-sys serve             # Start MCP server
ctx-sys watch             # Watch and auto-index

# Embeddings & Summaries
ctx-sys embed             # Generate embeddings
ctx-sys embed-status      # Embedding coverage
ctx-sys summarize         # Generate LLM summaries

# Graph
ctx-sys graph <entity>    # Traverse relationships
ctx-sys graph-stats       # Graph statistics
ctx-sys relationships     # List relationships

# Sessions & Analytics
ctx-sys sessions          # List sessions
ctx-sys messages          # View messages
ctx-sys analytics         # Usage analytics
ctx-sys dashboard         # Project dashboard
```

## Updating

```bash
npm update -g ctx-sys
```

## Uninstalling

```bash
npm uninstall -g ctx-sys

# Optionally remove project data
rm -rf your-project/.ctx-sys
```

## Troubleshooting

### "Command not found: ctx-sys"

Ensure npm global bin directory is in your PATH:

```bash
# Find npm global bin path
npm bin -g

# Add to your shell config (~/.bashrc or ~/.zshrc)
export PATH="$(npm bin -g):$PATH"
```

### "Ollama not found"

Install Ollama and ensure it's running:

```bash
# Install Ollama
curl https://ollama.ai/install.sh | sh

# Start Ollama service
ollama serve

# Pull the embedding model
ollama pull nomic-embed-text
```

### Database Errors

Reset the database:

```bash
rm .ctx-sys/ctx-sys.db
ctx-sys index
```

## Next Steps

- [Connect to Claude Desktop](/docs/guides/claude-integration)
- [Configure your project](/docs/guides/configuration)
