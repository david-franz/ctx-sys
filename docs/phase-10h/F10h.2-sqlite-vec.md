# F10h.2: Native Vector Search with sqlite-vec

**Phase**: 10h - Infrastructure & Performance
**Priority**: High
**Dependencies**: None (backward-compatible migration)

## Problem

Vector similarity search is the performance bottleneck in ctx-sys. Every semantic search query requires:

1. Fetching **all** vectors from SQLite as JSON strings
2. Parsing each JSON string into a `number[]` array
3. Computing cosine similarity in JavaScript for every vector
4. Sorting and returning top-k results

This is O(n * d) where n = number of entities and d = vector dimensions (768 for nomic-embed-text). For the current ctx-sys codebase (~807 entities), this takes < 200ms and is fine. But it degrades badly at scale:

| Entities | Estimated Query Time | Acceptable? |
|----------|---------------------|-------------|
| 500 | ~50ms | Yes |
| 1,000 | ~100ms | Yes |
| 5,000 | ~500ms | Borderline |
| 10,000 | ~1s | No |
| 50,000 | ~5s | Broken |

Large monorepos (10k+ files with multiple symbols per file) will hit 50k+ entities easily.

### Current Architecture

**Schema** (`src/db/schema.ts:102`):
```sql
-- Vector embeddings (stored as JSON since sql.js doesn't support sqlite-vec)
CREATE TABLE IF NOT EXISTS ${prefix}_vectors (
  id TEXT PRIMARY KEY,
  entity_id TEXT NOT NULL,
  model_id TEXT NOT NULL,
  embedding JSON NOT NULL,  -- JSON string: "[0.123, -0.456, ...]"
  content_hash TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (entity_id) REFERENCES ${prefix}_entities(id) ON DELETE CASCADE
);
```

**Similarity search** (`src/embeddings/manager.ts:141-184`):
```typescript
// Fetches ALL vectors, parses JSON, computes cosine similarity in JS
findSimilarByVector(queryVector: number[], options?: {
  limit?: number;
  threshold?: number;
  modelId?: string;
}) {
  const rows = this.db.exec(`SELECT * FROM ${this.vectorTable} WHERE model_id = ?`, [modelId]);
  // For each row: JSON.parse(row.embedding), cosineSimilarity(query, parsed)
  // Sort, filter, return top-k
}
```

### Why sqlite-vec?

[sqlite-vec](https://github.com/asg017/sqlite-vec) is a SQLite extension that provides:

- **Native vector storage** — `vec0` virtual table with efficient binary storage (not JSON)
- **KNN search** — `vec_distance_cosine()` function runs in native C, not JS
- **Approximate nearest neighbors** — Optional ANN indexes for sub-linear search
- **Binary compatibility** — Works with better-sqlite3 (our current driver)
- **Zero external dependencies** — Pure SQLite extension, no server required

Performance comparison (from sqlite-vec benchmarks):

| Operation | JSON + JS cosine | sqlite-vec |
|-----------|-----------------|------------|
| Storage per vector (768d) | ~6KB (JSON) | ~3KB (binary) |
| 1k vectors, top-10 | ~100ms | ~2ms |
| 10k vectors, top-10 | ~1s | ~15ms |
| 50k vectors, top-10 | ~5s | ~60ms |

~50-100x improvement in query time, ~50% reduction in storage.

## Implementation

### Step 1: Install sqlite-vec

```bash
npm install sqlite-vec
```

sqlite-vec provides a `loadable` function that returns the path to the native extension binary. Load it in the `DatabaseConnection` constructor.

**File**: `src/db/connection.ts`

```typescript
import * as sqliteVec from 'sqlite-vec';

export class DatabaseConnection {
  constructor(dbPath: string) {
    this.db = new BetterSqlite3(dbPath);

    // Load sqlite-vec extension
    sqliteVec.load(this.db);

    this.db.pragma('foreign_keys = ON');
    this.db.pragma('journal_mode = WAL');
  }
}
```

### Step 2: Migrate vector table schema

**File**: `src/db/schema.ts`

Replace the JSON-based vectors table with a `vec0` virtual table plus a metadata table.

**New schema:**
```sql
-- Vector metadata (keeps entity_id, model_id, content_hash linkage)
CREATE TABLE IF NOT EXISTS ${prefix}_vector_meta (
  rowid INTEGER PRIMARY KEY AUTOINCREMENT,
  entity_id TEXT NOT NULL,
  model_id TEXT NOT NULL,
  content_hash TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (entity_id) REFERENCES ${prefix}_entities(id) ON DELETE CASCADE,
  UNIQUE(entity_id, model_id)
);

-- Native vector storage via sqlite-vec
CREATE VIRTUAL TABLE IF NOT EXISTS ${prefix}_vec USING vec0(
  embedding float[768]
);
```

The `vec0` table uses integer rowid as its primary key. The `_vector_meta` table links rowids to entity_id/model_id. This separation is required because `vec0` virtual tables only support rowid + vector columns.

**Multi-dimension support**: Since different embedding models have different dimensions (768 for nomic-embed-text, 1024 for mxbai-embed-large), use separate `vec0` tables per model dimension, or use the maximum dimension and zero-pad. The simplest approach: one vec0 table per project with a fixed dimension matching the configured embedding model.

### Step 3: Migrate EmbeddingManager

**File**: `src/embeddings/manager.ts`

Replace `findSimilarByVector` with native vec0 query:

```typescript
findSimilarByVector(queryVector: number[], options?: {
  limit?: number;
  threshold?: number;
  modelId?: string;
}): SimilarityResult[] {
  const limit = options?.limit || 10;
  const modelId = options?.modelId || this.getDefaultModelId();

  // Native sqlite-vec KNN query
  const rows = this.db.exec(`
    SELECT
      vm.entity_id,
      vm.model_id,
      vec_distance_cosine(v.embedding, ?) AS distance
    FROM ${this.vecTable} v
    JOIN ${this.vectorMetaTable} vm ON vm.rowid = v.rowid
    WHERE vm.model_id = ?
    ORDER BY distance ASC
    LIMIT ?
  `, [
    new Float32Array(queryVector),  // sqlite-vec accepts Float32Array
    modelId,
    limit
  ]);

  return rows
    .filter(r => (1 - r.distance) >= (options?.threshold || 0))
    .map(r => ({
      entityId: r.entity_id,
      score: 1 - r.distance,  // Convert distance to similarity
      modelId: r.model_id
    }));
}
```

**Key changes:**
- `vec_distance_cosine()` returns a distance (0 = identical), not similarity (1 = identical)
- Convert: `similarity = 1 - distance`
- Pass query vector as `Float32Array`, not JSON string
- The `ORDER BY distance ASC` + `LIMIT` is handled natively by sqlite-vec (no full scan)

Replace `embed` (insert) method:

```typescript
async embed(entityId: string, content: string): Promise<void> {
  const embedding = await this.provider.embed(content);
  const modelId = this.provider.getModelIdentifier();

  // Insert metadata
  const meta = this.db.exec(`
    INSERT OR REPLACE INTO ${this.vectorMetaTable} (entity_id, model_id, content_hash)
    VALUES (?, ?, ?)
    RETURNING rowid
  `, [entityId, modelId, hashContent(content)]);

  const rowid = meta[0].rowid;

  // Insert vector into vec0 table
  this.db.exec(`
    INSERT OR REPLACE INTO ${this.vecTable} (rowid, embedding)
    VALUES (?, ?)
  `, [rowid, new Float32Array(embedding)]);
}
```

### Step 4: Data migration

**File**: `src/db/migrations.ts`

Add a migration that converts existing JSON vectors to native format:

```typescript
async function migrateVectorsToVec0(db: DatabaseConnection, prefix: string): Promise<void> {
  // 1. Create new tables
  db.exec(`CREATE TABLE IF NOT EXISTS ${prefix}_vector_meta (...)`);
  db.exec(`CREATE VIRTUAL TABLE IF NOT EXISTS ${prefix}_vec USING vec0(embedding float[768])`);

  // 2. Read existing JSON vectors
  const rows = db.exec(`SELECT * FROM ${prefix}_vectors`);

  // 3. Insert into new tables
  for (const row of rows) {
    const embedding = JSON.parse(row.embedding);

    // Insert metadata
    const meta = db.exec(`
      INSERT INTO ${prefix}_vector_meta (entity_id, model_id, content_hash, created_at)
      VALUES (?, ?, ?, ?)
      RETURNING rowid
    `, [row.entity_id, row.model_id, row.content_hash, row.created_at]);

    // Insert vector
    db.exec(`
      INSERT INTO ${prefix}_vec (rowid, embedding)
      VALUES (?, ?)
    `, [meta[0].rowid, new Float32Array(embedding)]);
  }

  // 4. Drop old table
  db.exec(`DROP TABLE IF EXISTS ${prefix}_vectors`);
}
```

**Migration trigger**: Run automatically on database open if `${prefix}_vectors` table exists but `${prefix}_vec` does not.

### Step 5: Update schema creation

**File**: `src/db/schema.ts`

Update `createProjectTables()` to use the new schema for fresh projects. Keep `createLegacyVectorTable()` available for the migration path.

### Step 6: Update embedBatch

**File**: `src/embeddings/manager.ts`

The batch embedding method needs to insert vectors transactionally:

```typescript
async embedBatch(items: Array<{ id: string; content: string }>): Promise<void> {
  const embeddings = await this.provider.embedBatch(items.map(i => i.content));

  this.db.transaction(() => {
    for (let i = 0; i < items.length; i++) {
      const modelId = this.provider.getModelIdentifier();

      // Upsert metadata
      const stmt = this.db.prepare(`
        INSERT OR REPLACE INTO ${this.vectorMetaTable} (entity_id, model_id, content_hash)
        VALUES (?, ?, ?)
      `);
      stmt.run(items[i].id, modelId, hashContent(items[i].content));

      // Get rowid
      const row = this.db.prepare(
        `SELECT rowid FROM ${this.vectorMetaTable} WHERE entity_id = ? AND model_id = ?`
      ).get(items[i].id, modelId);

      // Insert vector
      this.db.prepare(`
        INSERT OR REPLACE INTO ${this.vecTable} (rowid, embedding)
        VALUES (?, ?)
      `).run(row.rowid, new Float32Array(embeddings[i]));
    }
  })();
}
```

### Step 7: Update deleteForEntity

```typescript
async deleteForEntity(entityId: string): Promise<void> {
  // Get rowids to delete from vec0
  const rows = this.db.exec(
    `SELECT rowid FROM ${this.vectorMetaTable} WHERE entity_id = ?`,
    [entityId]
  );

  for (const row of rows) {
    this.db.exec(`DELETE FROM ${this.vecTable} WHERE rowid = ?`, [row.rowid]);
  }

  this.db.exec(`DELETE FROM ${this.vectorMetaTable} WHERE entity_id = ?`, [entityId]);
}
```

### Step 8: Update getEmbedding, hasEmbedding, getStats

These utility methods need to query the new table structure:

```typescript
async getEmbedding(entityId: string): Promise<number[] | null> {
  const meta = this.db.prepare(
    `SELECT rowid FROM ${this.vectorMetaTable} WHERE entity_id = ? AND model_id = ?`
  ).get(entityId, this.getDefaultModelId());

  if (!meta) return null;

  const vec = this.db.prepare(
    `SELECT embedding FROM ${this.vecTable} WHERE rowid = ?`
  ).get(meta.rowid);

  return vec ? Array.from(vec.embedding as Float32Array) : null;
}

async hasEmbedding(entityId: string): Promise<boolean> {
  const row = this.db.prepare(
    `SELECT 1 FROM ${this.vectorMetaTable} WHERE entity_id = ? LIMIT 1`
  ).get(entityId);
  return !!row;
}

async getStats(): Promise<{ total: number; byModel: Record<string, number> }> {
  const total = this.db.prepare(
    `SELECT COUNT(*) as count FROM ${this.vectorMetaTable}`
  ).get().count;

  const byModel = this.db.prepare(
    `SELECT model_id, COUNT(*) as count FROM ${this.vectorMetaTable} GROUP BY model_id`
  ).all();

  return { total, byModel: Object.fromEntries(byModel.map(r => [r.model_id, r.count])) };
}
```

### Step 9: Update export/import

**File**: `src/cli/debug.ts` (or wherever export/import lives)

Export needs to serialize vectors from `vec0` back to JSON for portability:

```typescript
// Export: read from vec0, convert Float32Array to JSON array
const vectors = db.exec(`
  SELECT vm.entity_id, vm.model_id, vm.content_hash, v.embedding
  FROM ${prefix}_vec v
  JOIN ${prefix}_vector_meta vm ON vm.rowid = v.rowid
`);
// Convert Float32Array to number[] for JSON serialization

// Import: parse JSON array, insert as Float32Array into vec0
```

### Step 10: Update `ctx-sys doctor` (F10h.1)

Add a check for sqlite-vec extension availability:

```typescript
async function checkSqliteVec(db: DatabaseConnection): Promise<CheckResult> {
  try {
    const result = db.exec("SELECT vec_version()");
    return { name: 'sqlite-vec', status: 'ok', detail: `v${result[0].vec_version}` };
  } catch {
    return { name: 'sqlite-vec', status: 'fail', detail: 'Extension not loaded', fix: 'npm install sqlite-vec' };
  }
}
```

## Files Changed

| File | Change |
|------|--------|
| `package.json` | Add `sqlite-vec` dependency |
| `src/db/connection.ts` | Load sqlite-vec extension on construction |
| `src/db/schema.ts` | New `_vector_meta` + `_vec` tables, remove JSON `_vectors` table |
| `src/db/migrations.ts` | JSON → vec0 migration function |
| `src/embeddings/manager.ts` | Rewrite vector CRUD to use vec0 + Float32Array |
| `src/cli/debug.ts` | Update export/import for new vector format |
| `src/cli/doctor.ts` | Add sqlite-vec version check |
| Tests | Update vector-related test fixtures |

## Rollback Plan

If sqlite-vec causes issues (platform incompatibility, build failures):

1. The migration is one-way but data-preserving (vectors are regeneratable from entities + Ollama)
2. Worst case: delete vec tables, recreate legacy `_vectors` table, run `ctx-sys embed . --force`
3. sqlite-vec is a pure C extension with prebuilt binaries for macOS/Linux/Windows — platform issues are unlikely

## Performance Targets

After migration:

| Metric | Current | Target |
|--------|---------|--------|
| 1k entity search | ~100ms | < 5ms |
| 10k entity search | ~1s | < 20ms |
| Storage per vector (768d) | ~6KB | ~3KB |
| Batch insert 1k vectors | ~2s | ~500ms |
| Database size (1k entities + vectors) | ~8MB | ~5MB |

## Success Criteria

- `npm run build` succeeds with sqlite-vec loaded
- Existing databases auto-migrate on first open (JSON → vec0)
- `ctx-sys embed .` writes to vec0 table
- `ctx-sys context "query"` uses native vec_distance_cosine
- Semantic search is 10x+ faster at 1k+ entities
- Export/import round-trips preserve vectors
- `ctx-sys doctor` reports sqlite-vec version
- All existing tests pass (with updated fixtures)
