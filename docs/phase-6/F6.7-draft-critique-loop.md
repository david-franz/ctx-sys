# F6.7 Draft-Critique Loop

**Phase**: 6 - Advanced Retrieval
**Priority**: Medium
**Dependencies**: F6.2 Multi-Strategy Search, F6.3 Context Assembly, F7.2 Model Abstraction

## Goal

Implement a self-critique mechanism that validates draft answers against source documents to catch hallucinations and improve response quality.

## Overview

After retrieving context and generating a draft answer, the critique stage:
1. Reviews the draft against source documents
2. Checks for hallucinations (claims not supported by sources)
3. Identifies missing information
4. Suggests improvements
5. Optionally revises the answer

This "generate then verify" pattern significantly improves answer quality and reduces hallucinations.

## Data Model

```typescript
interface DraftCritiqueRequest {
  query: string;
  draft: string;
  sources: SourceDocument[];
  options?: CritiqueOptions;
}

interface SourceDocument {
  id: string;
  content: string;
  type: string;           // 'code', 'doc', 'decision', etc.
  path?: string;
  relevanceScore?: number;
}

interface CritiqueOptions {
  strictness: 'lenient' | 'moderate' | 'strict';
  checkFactual: boolean;     // Verify facts against sources
  checkCompleteness: boolean; // Check for missing info
  checkContradictions: boolean;
  autoRevise: boolean;       // Automatically fix issues
  maxRevisions: number;
}

interface CritiqueResult {
  isValid: boolean;
  confidence: number;
  issues: CritiqueIssue[];
  suggestions: string[];
  revisedDraft?: string;    // If autoRevise enabled
  metadata: {
    factsChecked: number;
    factsVerified: number;
    sourcesUsed: string[];
    critiqueTimeMs: number;
  };
}

interface CritiqueIssue {
  type: 'hallucination' | 'unsupported' | 'incomplete' | 'contradiction' | 'outdated';
  severity: 'low' | 'medium' | 'high';
  description: string;
  location?: string;        // Where in the draft
  suggestion?: string;      // How to fix
  relatedSource?: string;   // Source that contradicts/supports
}
```

## Implementation

### File: `src/retrieval/critique.ts`

```typescript
import { ModelProvider } from '../models/provider';

export class DraftCritique {
  private modelProvider: ModelProvider;

  constructor(
    modelProvider: ModelProvider,
    private defaultOptions: CritiqueOptions = defaultCritiqueOptions
  ) {
    this.modelProvider = modelProvider;
  }

  /**
   * Critique a draft answer against source documents
   */
  async critique(request: DraftCritiqueRequest): Promise<CritiqueResult> {
    const options = { ...this.defaultOptions, ...request.options };
    const startTime = Date.now();

    // Step 1: Identify claims in the draft
    const claims = await this.extractClaims(request.draft, request.query);

    // Step 2: Verify each claim against sources
    const verificationResults = await this.verifyClaims(claims, request.sources);

    // Step 3: Check for missing information
    const missingInfo = options.checkCompleteness
      ? await this.checkCompleteness(request.query, request.draft, request.sources)
      : [];

    // Step 4: Compile issues
    const issues = this.compileIssues(verificationResults, missingInfo, options);

    // Step 5: Optionally revise
    let revisedDraft: string | undefined;
    if (options.autoRevise && issues.length > 0) {
      revisedDraft = await this.reviseDraft(request, issues, options.maxRevisions);
    }

    return {
      isValid: issues.filter(i => i.severity === 'high').length === 0,
      confidence: this.calculateConfidence(verificationResults),
      issues,
      suggestions: this.generateSuggestions(issues),
      revisedDraft,
      metadata: {
        factsChecked: claims.length,
        factsVerified: verificationResults.filter(v => v.verified).length,
        sourcesUsed: [...new Set(verificationResults.flatMap(v => v.sourcesUsed))],
        critiqueTimeMs: Date.now() - startTime
      }
    };
  }

  /**
   * Extract factual claims from the draft
   */
  private async extractClaims(draft: string, query: string): Promise<string[]> {
    const prompt = `Extract the factual claims from this answer that can be verified against source documents.

Query: ${query}

Answer: ${draft}

List each verifiable factual claim on a new line. Focus on:
- Specific code/function mentions
- Configuration values
- Process descriptions
- Technical specifications

Claims (one per line):`;

    const response = await this.modelProvider.complete({
      prompt,
      maxTokens: 500,
      temperature: 0.1
    });

    return response.text
      .split('\n')
      .map(line => line.replace(/^[-•*]\s*/, '').trim())
      .filter(line => line.length > 0);
  }

  /**
   * Verify claims against source documents
   */
  private async verifyClaims(
    claims: string[],
    sources: SourceDocument[]
  ): Promise<ClaimVerification[]> {
    const results: ClaimVerification[] = [];
    
    const sourcesText = sources
      .map((s, i) => `[Source ${i + 1}: ${s.path || s.type}]\n${s.content}`)
      .join('\n\n---\n\n');

    for (const claim of claims) {
      const verification = await this.verifySingleClaim(claim, sourcesText, sources);
      results.push(verification);
    }

    return results;
  }

  private async verifySingleClaim(
    claim: string,
    sourcesText: string,
    sources: SourceDocument[]
  ): Promise<ClaimVerification> {
    const prompt = `Verify if this claim is supported by the source documents.

Claim: "${claim}"

Sources:
${sourcesText}

Respond in JSON:
{
  "verified": true/false,
  "confidence": 0.0-1.0,
  "evidence": "quote or reference from sources if found",
  "sourcesUsed": [1, 2],  // Source numbers that support/contradict
  "issue": "description if not verified or partially verified"
}

JSON:`;

    const response = await this.modelProvider.complete({
      prompt,
      maxTokens: 200,
      temperature: 0.1
    });

    try {
      const parsed = JSON.parse(response.text.match(/\{[\s\S]*\}/)?.[0] || '{}');
      return {
        claim,
        verified: Boolean(parsed.verified),
        confidence: Number(parsed.confidence) || 0.5,
        evidence: parsed.evidence || '',
        sourcesUsed: (parsed.sourcesUsed || []).map((i: number) => sources[i - 1]?.id).filter(Boolean),
        issue: parsed.issue
      };
    } catch {
      return {
        claim,
        verified: false,
        confidence: 0.3,
        evidence: '',
        sourcesUsed: [],
        issue: 'Failed to verify claim'
      };
    }
  }

  /**
   * Check if the answer is complete
   */
  private async checkCompleteness(
    query: string,
    draft: string,
    sources: SourceDocument[]
  ): Promise<string[]> {
    const sourcesText = sources.map(s => s.content).join('\n\n');
    
    const prompt = `Given the query and sources, identify important information that's missing from the answer.

Query: ${query}

Answer: ${draft}

Available information in sources:
${sourcesText.slice(0, 2000)}

List missing important information (one per line), or write "COMPLETE" if the answer is comprehensive:`;

    const response = await this.modelProvider.complete({
      prompt,
      maxTokens: 300,
      temperature: 0.2
    });

    if (response.text.includes('COMPLETE')) {
      return [];
    }

    return response.text
      .split('\n')
      .map(line => line.replace(/^[-•*]\s*/, '').trim())
      .filter(line => line.length > 0 && !line.toLowerCase().includes('complete'));
  }

  /**
   * Compile all issues from verification results
   */
  private compileIssues(
    verifications: ClaimVerification[],
    missingInfo: string[],
    options: CritiqueOptions
  ): CritiqueIssue[] {
    const issues: CritiqueIssue[] = [];

    // Add unverified claims as issues
    for (const v of verifications) {
      if (!v.verified) {
        const severity = v.confidence < 0.3 ? 'high' : v.confidence < 0.6 ? 'medium' : 'low';
        issues.push({
          type: 'unsupported',
          severity,
          description: `Claim not supported by sources: "${v.claim}"`,
          suggestion: v.issue || 'Remove or verify this claim',
          relatedSource: v.sourcesUsed[0]
        });
      }
    }

    // Add missing information
    for (const missing of missingInfo) {
      issues.push({
        type: 'incomplete',
        severity: 'medium',
        description: `Missing information: ${missing}`,
        suggestion: `Consider adding information about: ${missing}`
      });
    }

    // Apply strictness filter
    if (options.strictness === 'lenient') {
      return issues.filter(i => i.severity === 'high');
    } else if (options.strictness === 'moderate') {
      return issues.filter(i => i.severity !== 'low');
    }
    
    return issues;
  }

  /**
   * Revise the draft to address issues
   */
  private async reviseDraft(
    request: DraftCritiqueRequest,
    issues: CritiqueIssue[],
    maxRevisions: number
  ): Promise<string> {
    const issueList = issues
      .map(i => `- [${i.severity}] ${i.description}`)
      .join('\n');

    const sourcesText = request.sources
      .map(s => `[${s.path || s.type}]: ${s.content}`)
      .join('\n\n');

    const prompt = `Revise this answer to address the identified issues.

Query: ${request.query}

Original answer: ${request.draft}

Issues to fix:
${issueList}

Available sources:
${sourcesText.slice(0, 3000)}

Provide a revised answer that:
1. Removes or corrects unsupported claims
2. Adds missing important information
3. Only makes claims supported by the sources
4. Maintains a helpful, clear tone

Revised answer:`;

    const response = await this.modelProvider.complete({
      prompt,
      maxTokens: 1000,
      temperature: 0.3
    });

    return response.text.trim();
  }

  private calculateConfidence(verifications: ClaimVerification[]): number {
    if (verifications.length === 0) return 0.5;
    
    const avgConfidence = verifications.reduce((sum, v) => sum + v.confidence, 0) / verifications.length;
    const verifiedRatio = verifications.filter(v => v.verified).length / verifications.length;
    
    return (avgConfidence + verifiedRatio) / 2;
  }

  private generateSuggestions(issues: CritiqueIssue[]): string[] {
    return issues
      .filter(i => i.suggestion)
      .map(i => i.suggestion!);
  }
}

interface ClaimVerification {
  claim: string;
  verified: boolean;
  confidence: number;
  evidence: string;
  sourcesUsed: string[];
  issue?: string;
}

const defaultCritiqueOptions: CritiqueOptions = {
  strictness: 'moderate',
  checkFactual: true,
  checkCompleteness: true,
  checkContradictions: true,
  autoRevise: false,
  maxRevisions: 1
};
```

### Integration with Query Pipeline

```typescript
// In src/retrieval/pipeline.ts

export class RetrievalPipeline {
  private critique: DraftCritique;
  
  async queryWithCritique(
    query: string,
    options: PipelineOptions
  ): Promise<PipelineResult> {
    // Step 1: Retrieve context
    const searchResults = await this.search.search(query, options);
    const context = this.assembleContext(searchResults);
    
    // Step 2: Generate draft (if requested)
    if (!options.generateAnswer) {
      return { context, searchResults };
    }
    
    const draft = await this.generateDraft(query, context);
    
    // Step 3: Critique (if enabled)
    if (options.enableCritique) {
      const critiqueResult = await this.critique.critique({
        query,
        draft,
        sources: searchResults.results.map(r => ({
          id: r.entity.id,
          content: r.entity.content,
          type: r.entity.type,
          path: r.entity.metadata?.path,
          relevanceScore: r.score
        })),
        options: options.critiqueOptions
      });
      
      return {
        context,
        searchResults,
        draft: critiqueResult.revisedDraft || draft,
        critique: critiqueResult
      };
    }
    
    return { context, searchResults, draft };
  }
}
```

## MCP Tool

```typescript
{
  name: 'critique_answer',
  description: 'Validate an answer against source documents to check for hallucinations',
  inputSchema: {
    type: 'object',
    properties: {
      query: { type: 'string', description: 'Original query' },
      draft: { type: 'string', description: 'Draft answer to critique' },
      sourceIds: { 
        type: 'array', 
        items: { type: 'string' },
        description: 'Entity IDs to use as sources'
      },
      autoRevise: { type: 'boolean', description: 'Automatically fix issues' },
      strictness: { 
        type: 'string', 
        enum: ['lenient', 'moderate', 'strict']
      }
    },
    required: ['query', 'draft', 'sourceIds']
  }
}
```

## Examples

### Example 1: Hallucination Detected

**Query**: "What's the maximum file upload size?"

**Draft**: "The maximum file upload size is 100MB."

**Sources**:
- Doc A: "Free tier: 10MB limit"
- Doc B: "Pro tier: 100MB limit"

**Critique Result**:
```json
{
  "isValid": false,
  "confidence": 0.6,
  "issues": [
    {
      "type": "incomplete",
      "severity": "high",
      "description": "Answer assumes Pro tier without clarification",
      "suggestion": "Specify that limit varies by tier"
    }
  ],
  "revisedDraft": "The maximum file upload size depends on your tier: Free users have a 10MB limit, while Pro users can upload files up to 100MB."
}
```

### Example 2: Valid Answer

**Query**: "How does AuthService handle token refresh?"

**Draft**: "AuthService uses a refresh token stored in httpOnly cookies. When the access token expires, it automatically calls `/auth/refresh` to get a new one."

**Sources**:
- AuthService.ts: Contains `refreshToken()` method using httpOnly cookies
- auth-routes.ts: Shows `/auth/refresh` endpoint

**Critique Result**:
```json
{
  "isValid": true,
  "confidence": 0.95,
  "issues": [],
  "metadata": {
    "factsChecked": 3,
    "factsVerified": 3,
    "sourcesUsed": ["AuthService.ts", "auth-routes.ts"]
  }
}
```

## Configuration

```yaml
# ctx-sys.yaml
retrieval:
  critique:
    enabled: true
    defaultStrictness: moderate
    checkFactual: true
    checkCompleteness: true
    checkContradictions: true
    autoRevise: false
    maxRevisions: 1
    # Skip critique for simple/short answers
    minDraftLength: 50
```

## Testing

```typescript
describe('DraftCritique', () => {
  it('should detect unsupported claims', async () => {
    const result = await critique.critique({
      query: 'What is the timeout?',
      draft: 'The timeout is 30 seconds.',
      sources: [{ id: '1', content: 'Timeout: 60 seconds', type: 'doc' }]
    });
    
    expect(result.isValid).toBe(false);
    expect(result.issues).toContainEqual(
      expect.objectContaining({ type: 'unsupported' })
    );
  });

  it('should pass valid answers', async () => {
    const result = await critique.critique({
      query: 'What is the timeout?',
      draft: 'The timeout is 60 seconds.',
      sources: [{ id: '1', content: 'Timeout: 60 seconds', type: 'doc' }]
    });
    
    expect(result.isValid).toBe(true);
    expect(result.confidence).toBeGreaterThan(0.8);
  });

  it('should auto-revise when enabled', async () => {
    const result = await critique.critique({
      query: 'What is the limit?',
      draft: 'The limit is 100.',
      sources: [
        { id: '1', content: 'Free: 10', type: 'doc' },
        { id: '2', content: 'Pro: 100', type: 'doc' }
      ],
      options: { autoRevise: true }
    });
    
    expect(result.revisedDraft).toContain('Free');
    expect(result.revisedDraft).toContain('Pro');
  });
});
```

## Performance Considerations

- **Claim extraction**: ~200ms per draft
- **Verification**: ~100ms per claim (parallelizable)
- **Caching**: Cache claim extractions for similar drafts
- **Batching**: Verify multiple claims in single model call when possible

## Metrics to Track

| Metric | Description |
|--------|-------------|
| `critique_hallucination_rate` | % of drafts with hallucinations |
| `critique_revision_rate` | % of answers that needed revision |
| `critique_latency_ms` | Time for full critique cycle |
| `critique_confidence_avg` | Average confidence score |
| `claims_per_draft` | Average claims extracted |
