# F10i.10 Clean Error Messages

**Phase**: 10i - Code Quality & Infrastructure
**Priority**: High
**Dependencies**: F10i.3 (logging abstraction — for non-fatal error reporting)

## Goal

Replace raw exception leaks, silent failures, and generic error messages with structured, actionable errors that tell the user (or LLM) what went wrong, why, and how to fix it.

## Current State

### No error taxonomy

Zero custom error classes exist. Every error is a bare `throw new Error(string)`. There is no way to programmatically distinguish "Ollama is down" from "wrong model" from "database locked" from "entity not found".

### Raw `TypeError: fetch failed` is the #1 user-facing problem

When Ollama is not running, 6+ locations throw a raw `TypeError: fetch failed` with the underlying `ECONNREFUSED` buried in the `.cause` chain. The user or LLM sees a completely opaque message with no guidance.

| Location | Caller | What Leaks |
|----------|--------|------------|
| `src/embeddings/ollama.ts` — `embed()` | index, add_entity, context_query | `TypeError: fetch failed` |
| `src/embeddings/ollama.ts` — `embedBatch()` | index | `TypeError: fetch failed` |
| `src/summarization/providers/ollama.ts` — `summarize()` | summarize_session | `TypeError: fetch failed` |
| `src/retrieval/hyde-expander.ts` — `generate()` | context_query with hyde=true | `TypeError: fetch failed` |
| `src/retrieval/llm-reranker.ts` — `callLLM()` | context_query | `TypeError: fetch failed` |
| `src/models/provider-factory.ts` — `complete()` | health checks | `TypeError: fetch failed` |

### Silent data corruption

`embedBatch()` falls back to zero vectors when individual embeddings fail. The caller gets a count of failures but no explanation. Those entities will never match any semantic query — silently broken.

### Generic "Failed to create X" messages

Several stores throw `Failed to create entity`, `Failed to update entity`, `Failed to create project`, `Failed to create relationship` with no indication of why (duplicate name? schema mismatch? database locked?).

### MCP errors give no remediation guidance

The MCP server catches all exceptions and returns `{ error: "message" }`. The LLM receives no suggestion of what to try next. For example, when Ollama is down during `index_codebase`, the LLM gets `TypeError: fetch failed` and has no idea it should tell the user to start Ollama.

## Implementation Plan

### Step 1: Create error class hierarchy

**File**: `src/errors.ts`

```typescript
/**
 * Base error for all ctx-sys errors.
 * Carries a user-facing message, an error code, and an optional fix suggestion.
 */
export class CtxError extends Error {
  constructor(
    message: string,
    public readonly code: ErrorCode,
    public readonly fix?: string,
    public readonly cause?: Error,
  ) {
    super(message);
    this.name = 'CtxError';
  }

  /** Format for CLI output */
  toUserString(): string {
    let msg = this.message;
    if (this.fix) msg += `\n  Fix: ${this.fix}`;
    return msg;
  }

  /** Format for MCP tool response */
  toMcpResponse(): { error: string; code: string; fix?: string } {
    return {
      error: this.message,
      code: this.code,
      fix: this.fix,
    };
  }
}

export type ErrorCode =
  | 'OLLAMA_UNAVAILABLE'
  | 'OLLAMA_MODEL_NOT_FOUND'
  | 'OLLAMA_REQUEST_FAILED'
  | 'EMBEDDING_FAILED'
  | 'SQLITE_VEC_UNAVAILABLE'
  | 'DATABASE_ERROR'
  | 'DATABASE_LOCKED'
  | 'PROJECT_NOT_FOUND'
  | 'PROJECT_EXISTS'
  | 'ENTITY_NOT_FOUND'
  | 'ENTITY_EXISTS'
  | 'SESSION_NOT_FOUND'
  | 'INVALID_INPUT'
  | 'FILE_NOT_FOUND'
  | 'PARSE_ERROR'
  | 'PROVIDER_UNAVAILABLE';

/**
 * Ollama is not reachable at the configured URL.
 */
export class OllamaUnavailableError extends CtxError {
  constructor(url: string, cause?: Error) {
    super(
      `Cannot connect to Ollama at ${url}`,
      'OLLAMA_UNAVAILABLE',
      `Start Ollama with: ollama serve\nOr check your config: ctx-sys doctor`,
      cause,
    );
    this.name = 'OllamaUnavailableError';
  }
}

/**
 * The requested model is not pulled in Ollama.
 */
export class OllamaModelNotFoundError extends CtxError {
  constructor(model: string, cause?: Error) {
    super(
      `Ollama model "${model}" is not available`,
      'OLLAMA_MODEL_NOT_FOUND',
      `Pull the model with: ollama pull ${model}`,
      cause,
    );
    this.name = 'OllamaModelNotFoundError';
  }
}

/**
 * A resource (project, entity, session) was not found.
 */
export class NotFoundError extends CtxError {
  constructor(resource: string, identifier: string) {
    super(
      `${resource} not found: ${identifier}`,
      resource === 'Project' ? 'PROJECT_NOT_FOUND'
        : resource === 'Session' ? 'SESSION_NOT_FOUND'
        : 'ENTITY_NOT_FOUND',
    );
    this.name = 'NotFoundError';
  }
}

/**
 * A resource already exists (duplicate name, etc.).
 */
export class AlreadyExistsError extends CtxError {
  constructor(resource: string, identifier: string) {
    super(
      `${resource} already exists: ${identifier}`,
      resource === 'Project' ? 'PROJECT_EXISTS' : 'ENTITY_EXISTS',
    );
    this.name = 'AlreadyExistsError';
  }
}

/**
 * Database operation failed.
 */
export class DatabaseError extends CtxError {
  constructor(operation: string, cause?: Error) {
    const isLocked = cause?.message?.includes('database is locked');
    super(
      isLocked
        ? `Database is locked — another process may be using it`
        : `Database error during ${operation}: ${cause?.message ?? 'unknown'}`,
      isLocked ? 'DATABASE_LOCKED' : 'DATABASE_ERROR',
      isLocked ? 'Close other ctx-sys processes and try again' : undefined,
      cause,
    );
    this.name = 'DatabaseError';
  }
}

/**
 * No embedding or summarization provider is available.
 */
export class ProviderUnavailableError extends CtxError {
  constructor(type: 'embedding' | 'summarization', tried: string[]) {
    super(
      `No ${type} provider available (tried: ${tried.join(', ')})`,
      'PROVIDER_UNAVAILABLE',
      `Ensure Ollama is running: ollama serve\nOr configure an OpenAI API key in ~/.ctx-sys/config.yaml`,
    );
    this.name = 'ProviderUnavailableError';
  }
}
```

### Step 2: Wrap Ollama fetch calls

Create a shared fetch wrapper that catches connectivity errors and throws structured errors:

**File**: `src/utils/ollama-fetch.ts`

```typescript
import { OllamaUnavailableError, OllamaModelNotFoundError, CtxError } from '../errors.js';

/**
 * Fetch wrapper for Ollama API calls.
 * Converts raw network errors into actionable CtxError subclasses.
 */
export async function ollamaFetch(
  url: string,
  options: RequestInit,
): Promise<Response> {
  try {
    const response = await fetch(url, options);

    if (!response.ok) {
      const body = await response.text().catch(() => '');

      // Model not found (404 or specific error message)
      if (response.status === 404 || body.includes('model') && body.includes('not found')) {
        const model = tryExtractModel(options.body);
        throw new OllamaModelNotFoundError(model ?? 'unknown');
      }

      throw new CtxError(
        `Ollama request failed (${response.status}): ${body || response.statusText}`,
        'OLLAMA_REQUEST_FAILED',
      );
    }

    return response;
  } catch (error) {
    // Already a CtxError — rethrow as-is
    if (error instanceof CtxError) throw error;

    // Network error — Ollama is not reachable
    if (error instanceof TypeError && error.message.includes('fetch failed')) {
      const baseUrl = new URL(url).origin;
      throw new OllamaUnavailableError(baseUrl, error as Error);
    }

    // Unknown error — wrap it
    throw new CtxError(
      `Ollama request failed: ${error instanceof Error ? error.message : String(error)}`,
      'OLLAMA_REQUEST_FAILED',
      undefined,
      error instanceof Error ? error : undefined,
    );
  }
}

function tryExtractModel(body: BodyInit | null | undefined): string | null {
  if (typeof body === 'string') {
    try { return JSON.parse(body).model ?? null; } catch { return null; }
  }
  return null;
}
```

### Step 3: Replace raw fetch calls with ollamaFetch

Update every Ollama-calling location to use the wrapper:

**`src/embeddings/ollama.ts`** — `embed()`:
```typescript
// Before
const response = await fetch(`${this.config.baseUrl}/api/embed`, { ... });

// After
import { ollamaFetch } from '../utils/ollama-fetch.js';
const response = await ollamaFetch(`${this.config.baseUrl}/api/embed`, { ... });
```

Same change in:
- `src/embeddings/ollama.ts` — `embedBatch()`, `detectModelInfo()`
- `src/summarization/providers/ollama.ts` — `summarize()`
- `src/retrieval/hyde-expander.ts` — `OllamaHypotheticalProvider.generate()`
- `src/retrieval/llm-reranker.ts` — `callLLM()`
- `src/models/provider-factory.ts` — any direct Ollama fetch calls

After this step, every Ollama call failure produces either `OllamaUnavailableError` (with `fix: "ollama serve"`) or `OllamaModelNotFoundError` (with `fix: "ollama pull <model>"`). Raw `TypeError: fetch failed` never reaches the user.

### Step 4: Fix silent zero-vector corruption

**`src/embeddings/ollama.ts`** — `embedBatch()` fallback:

```typescript
// Before (silent corruption)
} catch {
  results.push(new Array(this.dimensions).fill(0));
}

// After (explicit failure tracking)
} catch (error) {
  // Do NOT store a zero vector — it corrupts search results.
  // Instead, record the failure and let the caller decide.
  failures.push({
    index: i,
    text: texts[i].slice(0, 100),
    error: error instanceof Error ? error.message : String(error),
  });
  results.push(null);  // null signals "not embedded"
}
```

Update `EmbeddingManager.embedIncremental()` to handle `null` results — skip storing the vector for that entity, and report failures with context:

```typescript
// In the result returned to the caller:
return {
  embedded: successCount,
  skipped: skipCount,
  failed: failures.length,
  failureReason: failures.length > 0 ? failures[0].error : undefined,
};
```

### Step 5: Wrap database operations in stores

Update `EntityStore`, `RelationshipStore`, `ProjectManager` to catch SQLite exceptions and rethrow as `DatabaseError`:

**`src/entities/store.ts`** — `create()`:
```typescript
// Before
const result = this.db.run(insertSql, params);
if (result.changes === 0) {
  throw new Error('Failed to create entity');
}

// After
try {
  const result = this.db.run(insertSql, params);
  if (result.changes === 0) {
    throw new AlreadyExistsError('Entity', input.name);
  }
} catch (error) {
  if (error instanceof CtxError) throw error;
  throw new DatabaseError('create entity', error instanceof Error ? error : undefined);
}
```

Apply the same pattern to:
- `EntityStore.update()` — line 211
- `EntityStore.upsert()` — line 68
- `RelationshipStore.upsert()` — line 49 (`Failed to create relationship`)
- `ProjectManager.create()` — line 60 (`Failed to create project`)
- `ProjectManager.update()` — line 163 (`Failed to update project`)

### Step 6: Update MCP error response format

**`src/mcp/server.ts`** — the catch block:

```typescript
// Before
} catch (error) {
  const message = error instanceof Error ? error.message : String(error);
  return {
    content: [{ type: 'text', text: JSON.stringify({ error: message }, null, 2) }],
    isError: true
  };
}

// After
} catch (error) {
  if (error instanceof CtxError) {
    return {
      content: [{ type: 'text', text: JSON.stringify(error.toMcpResponse(), null, 2) }],
      isError: true,
    };
  }
  // Unexpected error — still wrap for safety
  const message = error instanceof Error ? error.message : String(error);
  return {
    content: [{ type: 'text', text: JSON.stringify({ error: message, code: 'UNKNOWN' }, null, 2) }],
    isError: true,
  };
}
```

Now when the LLM calls `index_codebase` and Ollama is down, it receives:

```json
{
  "error": "Cannot connect to Ollama at http://localhost:11434",
  "code": "OLLAMA_UNAVAILABLE",
  "fix": "Start Ollama with: ollama serve\nOr check your config: ctx-sys doctor"
}
```

Instead of:

```json
{
  "error": "TypeError: fetch failed"
}
```

### Step 7: Update CLI error handler

**`src/cli/init.ts`** — update the `defaultOutput` and the shared catch pattern:

```typescript
// Centralized error handler for CLI commands
export function handleCliError(error: unknown, output: CLIOutput): never {
  if (error instanceof CtxError) {
    output.error(error.message);
    if (error.fix) {
      output.log(`  Fix: ${error.fix}`);
    }
    // In verbose mode, print the cause chain
    if (process.env.CTX_VERBOSE === '1' && error.cause) {
      output.log(`  Cause: ${error.cause.message}`);
      if (error.cause.stack) output.log(error.cause.stack);
    }
  } else {
    output.error(error instanceof Error ? error.message : String(error));
    if (process.env.CTX_VERBOSE === '1' && error instanceof Error && error.stack) {
      output.log(error.stack);
    }
  }
  process.exit(1);
}
```

Then replace the catch block in every CLI command:

```typescript
// Before (in 35+ locations)
} catch (error) {
  output.error(error instanceof Error ? error.message : String(error));
  process.exit(1);
}

// After
} catch (error) {
  handleCliError(error, output);
}
```

### Step 8: Add CTX_VERBOSE environment variable

For debugging, `CTX_VERBOSE=1` prints the cause chain and stack trace. This is simpler than a `--verbose` flag on every command and works for both CLI and MCP:

```bash
# Normal
$ ctx-sys index
Error: Cannot connect to Ollama at http://localhost:11434
  Fix: Start Ollama with: ollama serve

# Verbose
$ CTX_VERBOSE=1 ctx-sys index
Error: Cannot connect to Ollama at http://localhost:11434
  Fix: Start Ollama with: ollama serve
  Cause: TypeError: fetch failed
  at OllamaEmbeddingProvider.embed (...)
```

### Step 9: Add early Ollama connectivity check to indexing

Rather than failing deep inside the embedding pipeline, check Ollama connectivity early in high-level operations:

**`src/services/core-service.ts`** (or `indexing-service.ts`) — `indexCodebase()`:

```typescript
async indexCodebase(projectId: string, path: string, options?: IndexOptions): Promise<IndexResult> {
  // Pre-flight check: is Ollama reachable?
  const embeddingManager = await this.context.getEmbeddingManager(projectId);
  if (embeddingManager.provider instanceof OllamaEmbeddingProvider) {
    const available = await embeddingManager.provider.isAvailable();
    if (!available) {
      throw new OllamaUnavailableError(embeddingManager.provider.baseUrl);
    }
  }

  // ... proceed with indexing
}
```

This gives the user an immediate, clear error before any work begins, instead of failing halfway through after indexing 500 files.

Apply the same pre-flight check to:
- `addEntity()` (when it generates an embedding)
- `queryContext()` with `hyde=true` (when it calls Ollama for HyDE)
- `summarizeSession()` (when it calls Ollama for summarization)

### Step 10: Update embedding failure reporting

**`src/embeddings/manager.ts`** — `embedIncremental()`:

```typescript
// Before
} catch {
  errors += batch.length;
}

// After
} catch (error) {
  errors += batch.length;
  if (!firstError) {
    firstError = error instanceof Error ? error.message : String(error);
  }
}

// At the end:
return {
  embedded,
  skipped,
  failed: errors,
  totalProcessed: embedded + skipped + errors,
  failureReason: errors > 0 ? firstError : undefined,
};
```

The CLI index command then shows:

```
Indexed 1,234 entities (892 embedded, 342 unchanged)
```

Or on failure:

```
Indexed 1,234 entities (0 embedded, 342 unchanged, 892 failed)
  Reason: Cannot connect to Ollama at http://localhost:11434
  Fix: Start Ollama with: ollama serve
  Note: Entities are indexed but semantic search won't work until embeddings are generated.
        Re-run with: ctx-sys index --force
```

## File Changes

| File | Change |
|------|--------|
| `src/errors.ts` | **New** — error class hierarchy (CtxError, OllamaUnavailableError, etc.) |
| `src/utils/ollama-fetch.ts` | **New** — shared fetch wrapper for Ollama API calls |
| `src/embeddings/ollama.ts` | **Update** — use `ollamaFetch`, fix zero-vector corruption |
| `src/embeddings/manager.ts` | **Update** — handle null embeddings, report failure reason |
| `src/summarization/providers/ollama.ts` | **Update** — use `ollamaFetch` |
| `src/retrieval/hyde-expander.ts` | **Update** — use `ollamaFetch` |
| `src/retrieval/llm-reranker.ts` | **Update** — use `ollamaFetch` |
| `src/models/provider-factory.ts` | **Update** — use `ollamaFetch`, throw `ProviderUnavailableError` |
| `src/entities/store.ts` | **Update** — wrap SQLite errors as `DatabaseError` |
| `src/graph/relationship-store.ts` | **Update** — wrap SQLite errors as `DatabaseError` |
| `src/project/manager.ts` | **Update** — wrap errors, use `AlreadyExistsError`/`NotFoundError` |
| `src/mcp/server.ts` | **Update** — structured error response with code + fix |
| `src/cli/init.ts` | **Update** — add `handleCliError()`, support `CTX_VERBOSE` |
| `src/cli/*.ts` (22 files) | **Update** — replace catch blocks with `handleCliError()` |
| `src/services/core-service.ts` | **Update** — add pre-flight Ollama checks |

## Error Message Examples

### Before vs After

**Ollama not running — CLI:**
```
# Before
Error: TypeError: fetch failed

# After
Error: Cannot connect to Ollama at http://localhost:11434
  Fix: Start Ollama with: ollama serve
       Or check your config: ctx-sys doctor
```

**Ollama not running — MCP:**
```json
// Before
{ "error": "TypeError: fetch failed" }

// After
{
  "error": "Cannot connect to Ollama at http://localhost:11434",
  "code": "OLLAMA_UNAVAILABLE",
  "fix": "Start Ollama with: ollama serve\nOr check your config: ctx-sys doctor"
}
```

**Model not pulled — CLI:**
```
# Before
Error: Ollama embedding failed (404):

# After
Error: Ollama model "mxbai-embed-large:latest" is not available
  Fix: Pull the model with: ollama pull mxbai-embed-large:latest
```

**Database locked:**
```
# Before
Error: SqliteError: database is locked

# After
Error: Database is locked — another process may be using it
  Fix: Close other ctx-sys processes and try again
```

**Entity not found:**
```
# Before
Error: Failed to update entity

# After
Error: Entity not found: my-function
```

**Indexing with Ollama down:**
```
# Before
Indexed 1,234 files
Error: TypeError: fetch failed

# After
Indexed 1,234 entities (0 embedded, 342 unchanged, 892 failed)
  Reason: Cannot connect to Ollama at http://localhost:11434
  Fix: Start Ollama with: ollama serve
  Note: Entities are indexed but semantic search won't work until embeddings are generated.
        Re-run with: ctx-sys index --force
```

## Testing

**File**: `tests/phase-10i/errors.test.ts`
- Test `OllamaUnavailableError` produces correct message, code, and fix
- Test `OllamaModelNotFoundError` includes model name in fix command
- Test `DatabaseError` detects "database is locked" and adds fix
- Test `CtxError.toMcpResponse()` includes all fields
- Test `CtxError.toUserString()` formats correctly

**File**: `tests/phase-10i/ollama-fetch.test.ts`
- Test `ollamaFetch` converts `TypeError: fetch failed` to `OllamaUnavailableError`
- Test `ollamaFetch` converts 404 to `OllamaModelNotFoundError`
- Test `ollamaFetch` passes through successful responses unchanged
- Test `ollamaFetch` preserves existing `CtxError` (no double-wrapping)

**File**: `tests/phase-10i/cli-error-handler.test.ts`
- Test `handleCliError` prints fix suggestion for `CtxError`
- Test `handleCliError` prints cause chain when `CTX_VERBOSE=1`
- Test `handleCliError` handles raw Error objects gracefully

## Success Criteria

- `TypeError: fetch failed` never reaches the user or LLM in any code path
- Every error from Ollama connectivity includes the fix command `ollama serve`
- Every error from a missing model includes the fix command `ollama pull <model>`
- Zero-vector corruption is eliminated — failed embeddings are skipped, not stored
- MCP error responses include `code` and `fix` fields
- CLI errors show fix suggestions inline
- `CTX_VERBOSE=1` shows full cause chains and stack traces
- Generic "Failed to create X" messages are replaced with specific reasons

## Tasks

- [ ] Create `src/errors.ts` with error class hierarchy
- [ ] Create `src/utils/ollama-fetch.ts` wrapper
- [ ] Replace raw `fetch` with `ollamaFetch` in 6 locations
- [ ] Fix zero-vector corruption in `embedBatch()`
- [ ] Wrap SQLite errors in `EntityStore`, `RelationshipStore`, `ProjectManager`
- [ ] Update MCP server error response format
- [ ] Create `handleCliError()` and update 22 CLI catch blocks
- [ ] Add pre-flight Ollama checks to `indexCodebase`, `addEntity`, `queryContext`
- [ ] Update embedding failure reporting with reason
- [ ] Add `CTX_VERBOSE` support
- [ ] Write error class unit tests
- [ ] Write `ollamaFetch` unit tests
- [ ] `tsc --noEmit` passes
- [ ] Run full test suite
