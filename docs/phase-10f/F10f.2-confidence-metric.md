# F10f.2 Fix Confidence Metric

**Phase**: 10f - Retrieval Quality
**Priority**: High
**Dependencies**: None

## Problem

The confidence metric is calculated as the simple arithmetic mean of all result scores:

```typescript
// src/services/core-service.ts:696-699
const avgRelevance = results.length > 0
  ? results.reduce((sum, r) => sum + r.score, 0) / results.length
  : 0;
```

This produces misleading numbers:

| Scenario | Scores | Current Confidence | Should Be |
|----------|--------|-------------------|-----------|
| 5 great results (50-70%) | [0.70, 0.60, 0.55, 0.52, 0.50] | 57% | ~60% (good) |
| 5 great + 15 garbage | [0.70, 0.60, 0.55, 0.52, 0.50, 0.16, 0.16, 0.16, ...] | 24% | ~55% (still good) |
| 20 garbage results | [0.02, 0.02, 0.01, 0.01, ...] | 1.5% | ~2% (bad) |
| Negative reranking | [..., -0.29] | -0% | 0% (nothing relevant) |

The presence of low-score tail results drags down the confidence even when the top results are excellent. Confidence should reflect **how good the best results are**, not average quality including noise.

## Implementation

### Replace mean with weighted top-k confidence

**File**: `src/services/core-service.ts`

Replace the confidence calculation (around line 696):

```typescript
// Old: simple mean of all scores
const avgRelevance = results.length > 0
  ? results.reduce((sum, r) => sum + r.score, 0) / results.length
  : 0;

// New: weighted top-k with diminishing contribution
function calculateConfidence(results: SearchResult[]): number {
  if (results.length === 0) return 0;

  // Sort by score descending (should already be sorted, but be safe)
  const sorted = [...results].sort((a, b) => b.score - a.score);

  // Take top 5 results with exponential decay weighting
  const k = Math.min(5, sorted.length);
  let weightedSum = 0;
  let totalWeight = 0;
  for (let i = 0; i < k; i++) {
    const weight = Math.pow(0.7, i);  // 1.0, 0.7, 0.49, 0.34, 0.24
    weightedSum += Math.max(0, sorted[i].score) * weight;
    totalWeight += weight;
  }

  return totalWeight > 0 ? weightedSum / totalWeight : 0;
}
```

### Rationale

- **Top-5 focus**: Confidence reflects the quality of what the user will actually see at the top
- **Exponential decay**: The #1 result matters most, #5 contributes ~24% as much
- **Floor at 0**: Negative scores (from reranking penalties) don't drag confidence below zero
- **No noise dilution**: 15 garbage results at the tail don't affect the metric

### Expected Results

| Scenario | Current | After Fix |
|----------|---------|-----------|
| Embedding query (good match) | 37% | ~54% |
| Auth query (no match) | -0% | ~2% |
| Mixed results | 24% | ~55% |

## Success Criteria

- Confidence > 50% when top results are genuinely relevant
- Confidence < 10% when nothing relevant is found
- Confidence is never negative
- The number makes intuitive sense when displayed
